# 基于论文摘要的文本分类与关键词抽取挑战赛

## 赛题分析

1. 类型一其实就是一个二分类文本分类赛题，如果是二分类的问题的话，其实使用统计学习的方法其实也可以达到一个比较好的分数。

2. 类型二比较偏向于NER的任务抽取任务（本次夏令营不涉及到）

## 比赛流程

1. 先跑了一遍基线脚本，直接在飞浆平台上运行的，然后提交了一份打卡信息。
2. 之前做过相关的文本分类的任务，前段时间，做一个文本分类的模型，基于BERT的模型改进。但是提交的分数不尽人意，百分之70几。当然纯BERT的在比较小的训练上，同一台机器上的跑出来的分数，相比改进前还是有些许的提升。
3. 提交完70几分的分数之后，Topline的代码结构，在之前的实验的时候，Topline的所提及到几个模型，都有使用过，但是分数相比的Topline的代码有很多的差距，后面仔细对比了与Topline的参数，参数一致的时候，训练仍然有差距，一开始怀疑是词向量训练的问题，但是在对比实验中，使用一样的机器跑了几个Epoch，对比了下，最后确定可能是将数据转成向量的这个过程中存在一定问题，可能丢失了一些信息。最近在向量可视化的相关工作，先画个饼，后面会将向量对比可视化结果，放在这个目录下面。后面可能使用其他的词嵌入模型，例如BGE这类比较新的模型,做词嵌入的工作，说不定会更好的效果。[BAAI/bge-large-zh · Hugging Face](https://huggingface.co/BAAI/bge-large-zh)

4. 关于比赛，整个比赛的流程还是比较顺利的，除了提交成绩之外以及卡在0.9995。
   1. 一开始提交的成绩的时候，提交错了测试集，分数很低，比基线低了很多，那个时候还觉得很奇怪为什么分数这么低，一开始用的模型是自己魔改的模型，在几个文本分类的数据集中，例如tnew等，都有一个看的去的分数，那段时间十分的苦恼不知道为什么。后面看文档的时候，以及从基线上下载的提交文件，作对比的时候发现，原来提交错了数据集，一开始没有发现这个这个错误主要是因为，在写入数据的时候，以提交文件的行数为写入。
   2. 关于分数卡在0.9995，这个时候其实离1已经很近了。但是一直没有跑出来1的分数，也一直没有提交了，打卡截止的当天，把最大序列长度加到的模型的最大长度，512的窗口，一共重复训练60个epoch，分了三次进行实验，每次实验使用上次实验的最优的权重，基本上训练后面，TrainLoss 稳定在0.0001 ，其余几个实验指标都在1。保存模型的最优判断，也修改成了在验证集的F1值以及训练损失的共同的作用，当然训练损失是更高的优先级的保存指标。
   3. 大概在45个epoch上的模型就停止了，然后验证最后拿到了1的分数。
5. 关于参数的调整。
   1. 其实本次任务还是比较偏向于长样本的分类任务，之前在第二点中所提及到的分数，基本是都没有采用全部数据输入到模型中，我是将题目的标题和关键词组成一条样本来训练，最后结果不太好。采用这样的方式的原因，受制于显卡大小以及查看了下数据的分布情况。后面的实验基本基本都是在本地调通之后，再放在云服务上，使用V100-32G，使用了两个平台的显卡，不同平台的同类型星卡也存在一定的性能差距。
   2. 最长序列长度，128 - 256 - 512 这几个版本都跑过，三种版本的结果，相对而言 256的序列长度性价比更高些，512对于显存的要求很高，32G的显存占用基本快满，代价有点大，当然换来就是更多的特征。
